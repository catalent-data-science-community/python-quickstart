{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Python\n",
    "---\n",
    "---\n",
    "The Process:\n",
    "1. [Import dependencies and configure settings](#Step-1:-Import-dependencies-and-configure-settings)\n",
    "2. [Load the data into python](#Step-2:-Load-the-data-into-python)\n",
    "3. [Create data views or new datasets by making more python objects](#Step-3:-Create-data-views-or-new-datasets-by-making-more-python-objects)\n",
    "4. [Lock down the process and store the final result in a reliable location](#Step-4:-Lock-down-the-process-and-store-the-final-result-in-a-reliable-location)\n",
    "\n",
    "![Lego-Data](../images/data_wrangling.jpg \"Lego Data Wrangling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import dependencies and configure settings\n",
    "### Import packages, modules, objects, or functions into the current notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TIP: Avoid 'from PACKAGE import \\*' syntax as it clutters your namespace with objects you may not be aware of***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEST PRACTICE: import built-in packages first\n",
    "# from PACKAGE import OBJECT lets us bring only what we need into our namespace\n",
    "from warnings import filterwarnings\n",
    "# import PACKAGE, brings the all modules into one object named PACKAGE\n",
    "import re\n",
    "\n",
    "# BEST PRACTICE: import third-party packages second\n",
    "# import PACKAGE as ALIAS, places all the modules into one object named ALIAS\n",
    "import bamboolib as bam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "# aliases can also be used when importing an individual module from the package\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# BEST PRACTICE: import custom packages last\n",
    "# for example: import custom_module as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure settings by using functions or methods (always check the documentation)\n",
    "Third-party packages used in this notebook:\n",
    "- [Bamboolib](https://docs.bamboolib.8080labs.com/documentation/getting-started)\n",
    "- [NumPy](https://numpy.org/doc/stable/user/index.html)\n",
    "- [Pandas](https://pandas.pydata.org/pandas-docs/version/1.2.4/user_guide/index.html)\n",
    "- [SciPy](https://docs.scipy.org/doc/scipy/tutorial/index.html)\n",
    "- [Statsmodels](https://www.statsmodels.org/devel/user-guide.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set python shell filter out warnings and avoid cluttering outputs\n",
    "filterwarnings(\n",
    "    'ignore'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set custom pandas package options by iterating through key-value pairs in a dictionary\n",
    "for option, value in { # dictionaries are denoted by curly brackets {} or the dict() function\n",
    "    'display.max_columns': 50,\n",
    "    'display.max_colwidth': None,\n",
    "    'display.max_info_columns': 50,\n",
    "    'display.max_rows': 20,\n",
    "    'display.precision': 4\n",
    "}.items(): # the .items() function of a dictionary lets us iterate through key, value pairs\n",
    "    # we can call a function on the variable we set for the objects we're iterating over\n",
    "    # in this case those variables are 'option', and 'value' and they represent\n",
    "    # the key, value pairs from the dictionary above\n",
    "    pd.set_option(\n",
    "        option, # this will be 'display.max_columns' etc..\n",
    "        value   # this will be 50, None, etc..\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Data-Wrangling-with-Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load the data into python\n",
    "### Use tools that 'open' files and load their contents into objects\n",
    "NOTE: It is possible to build custom functions to read files, but not advised as there are many python libraries that can do so while providing enhanced performance and additional functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load each dataset into a pandas DataFrame object\n",
    "cocoon_pharmacy_df = pd.read_csv(\n",
    "    # the read_csv function from the pandas package will read the file at this location\n",
    "    '../data/cocoon_pharmacy_location_added.csv'\n",
    ")\n",
    "data_literacy_df = pd.read_csv(\n",
    "    # the '..' notation indicates that parsing should begin at the parent folder \n",
    "    # of this notebook, so if this notebook is in the 'notebooks/' folder then\n",
    "    # '..' would map to the root folder of this repository (the parent of 'notebooks/') \n",
    "    '../data/data_literacy_questionnaire.csv'\n",
    ")\n",
    "data_journey_df = pd.read_csv(\n",
    "    '../data/data_journey_questionnaire.csv'\n",
    ")\n",
    "meeting_cadence_df = pd.read_csv(\n",
    "    '../data/meeting_cadence_survey.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Data-Wrangling-with-Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create data views or new datasets by making more python objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Use third-party tools for transforming data\n",
    "Bamboolib is our recommendation as it offers a great bridge into python, but any low/no-code solutions are a great place to get started with these concepts, and many such as JMP from SAS, Minitab, and Power BI also offer scripting integrations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Started with [Bamboolib](https://docs.bamboolib.8080labs.com/documentation/getting-started):**\n",
    "- [x] import the package *(completed at the beginning of this notebook)*\n",
    "\n",
    "- [x] create a Pandas DataFrame *(completed in the code cell above)*\n",
    "\n",
    "- [ ] display a pandas dataframe to make \"Show Bamboolib UI\" button available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TIP: DataFrames can be displayed by using the display() function or by placing the object on the last line of a cell***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Bamboolib will overwrite the contents of this cell after work is complete \n",
    "# with any code necessary to execute the requested transformations or plots\n",
    "cocoon_pharmacy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Bamboolib will overwrite the contents of this cell after work is complete \n",
    "# with any code necessary to execute the requested transformations or plots\n",
    "data_literacy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Bamboolib will overwrite the contents of this cell after work is complete \n",
    "# with any code necessary to execute the requested transformations or plots\n",
    "data_journey_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Bamboolib will overwrite the contents of this cell after work is complete \n",
    "# with any code necessary to execute the requested transformations or plots\n",
    "meeting_cadence_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Write code to transform the data\n",
    "Use the many packages available in Python to build flexible 'templated' solutions that address re-occurring issues or dynamic problems that require more complex integrations and/or additional capabilities *(Ex. networking, containerization/virtualization, multi-processing)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Started with writing 'Production' code:**\n",
    "- [x] Adhere to a consistent method for structuring and writing code *(see [PEP8](https://peps.python.org/pep-0008/) for more details)*\n",
    "\n",
    "- [x] Document third-party packages and the versions being used *(Ex. binder/requirements.txt file in this repository)*\n",
    "\n",
    "- [ ] Always test your code! *(Doesn't have to be automated, but 'good' code should always have error handling and logging)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***TIP: Check out the [Official Pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) for a Quick Syntax Reference***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We will populate this area with code for building a Machine Learning demo from the Cocoon Pharmacy Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top](#Data-Wrangling-with-Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Lock down the process and store the final result in a reliable location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Always save the data to a secure location, whether that's as a table in a relational database, as a flat file in an online file-system, or as a flat file in a physical drive that is that is consistently backed up *([See Pandas In/Out Methods](https://pandas.pydata.org/docs/reference/io.html))*\n",
    "\n",
    "- Whether or not a low-code tool was used, if any scripting/programming has been built, always try to follow best practice by 'committing' it to an online [Git](https://git-scm.com/book/en/v2/Getting-Started-What-is-Git%3F) Repository so that it can be securely backed up with an audit trail *([GitHub](https://github.com/) and [Azure DevOps Services](https://azure.microsoft.com/en-us/services/devops/) are both free for small teams)*\n",
    "\n",
    "- Make sure at any given time there is a good version of the code that 'always builds', meaning any future development work should occur on 'branches' (or copies) of the code before finalizing those changes on the good version *([see some methods for how to organize your development](https://medium.com/@patrickporto/4-branching-workflows-for-git-30d0aaee7bf))*\n",
    "\n",
    "- There is no such thing as documentation that is 'too descriptive'! It's highly unlikely it will ever be too much for any prospective users/contributors of bespoke code, and it diminishes the probability that the writer will tragically forget how exactly their code works *([which happens to the best of us](https://javascript.plainenglish.io/is-it-normal-to-forget-how-your-own-code-works-e5a6462f3571))*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38",
   "language": "python",
   "name": "conda-env-azureml_py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "065e060c6089993c74c9bf4b911d37e59dadeed66bb03a666c87bc53eaee6720"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
