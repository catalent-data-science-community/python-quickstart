{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import built-in packages first\n",
    "# from PACKAGE import OBJECT lets us bring only what we need into our namespace\n",
    "from warnings import filterwarnings\n",
    "# import PACAKGE, brings the all modules into one object named PACAKGE\n",
    "import re\n",
    "\n",
    "# import third-party packages second\n",
    "from geopy.geocoders import Nominatim as geopy_Nominatim\n",
    "from pandas_profiling import ProfileReport\n",
    "from nltk.tokenize import word_tokenize as nltk_word_tokenize\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer as nltk_WordNetLemmatizer\n",
    "from nltk.tag import pos_tag as nltk_pos_tag\n",
    "from wordcloud import (\n",
    "    # use parenthesis to import multiple objects and even add aliases\n",
    "    # an alias is what the object is called in our namespace\n",
    "    STOPWORDS as wordcloud_STOPWORDS,\n",
    "    WordCloud\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "# aliases can be added to the 'full' imports of packages\n",
    "import pandas as pd\n",
    "# aliases can also be added when importing just a particular module from the package\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "# AVOID: 'from PACKAGE import *' syntax as it clutters your namespace with objects you may not be aware of\n",
    "\n",
    "# import custom packages third\n",
    "# for example: import custom_module as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set python shell filter out warnings and avoid cluttering outputs\n",
    "filterwarnings(\n",
    "    'ignore'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set custom pandas package options by iterating through key-value pairs in a dictionary\n",
    "for option, value in { # dictionaries are denoted by curly brackets {} or the dict() function\n",
    "    'display.max_columns': 50,\n",
    "    'display.max_colwidth': None,\n",
    "    'display.max_info_columns': 50,\n",
    "    'display.max_rows': 20,\n",
    "    'display.precision': 4\n",
    "}.items(): # the .items() function of a dictionary lets us iterate through key, value pairs\n",
    "    # we can call a function on the variable we set for the objects we're iterating over\n",
    "    # in this case those variables are 'option', and 'value' and they represent\n",
    "    # the key, value pairs from the dictionary above\n",
    "    pd.set_option(\n",
    "        option, # this will be 'display.max_columns' etc..\n",
    "        value   # this will be 50, None, etc..\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load each dataset into a pandas DataFrame object\n",
    "cocoon_pharmacy_df = pd.read_csv(\n",
    "    '../data/cocoon_center_pharmacy.csv'\n",
    ")\n",
    "data_literacy_df = pd.read_csv(\n",
    "    '../data/data_literacy_questionnaire.csv'\n",
    ")\n",
    "data_journey_df = pd.read_csv(\n",
    "    '../data/data_journey_questionnaire.csv'\n",
    ")\n",
    "meeting_cadence_df = pd.read_csv(\n",
    "    '../data/meeting_cadence_survey.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an example function with one mandatory and one optional parameter\n",
    "def display_with_info(\n",
    "    dataframe: pd.DataFrame,\n",
    "    name: str = None\n",
    ") -> None:\n",
    "    # print dataframe name if passed\n",
    "    if name:\n",
    "        print(\n",
    "            '=' * len(name),\n",
    "            end = '\\n'\n",
    "        )\n",
    "        print(\n",
    "            name,\n",
    "            end = '\\n' + (\n",
    "                '=' * len(name)\n",
    "            ) + '\\n\\n'\n",
    "        )\n",
    "    # display dataframe information\n",
    "    display(\n",
    "        dataframe.info()\n",
    "    )\n",
    "    # label the next output\n",
    "    print(\n",
    "        # create the illusion of a border by using hyphens\n",
    "        '-' * 14\n",
    "    )\n",
    "    print(\n",
    "        'First Ten Rows',\n",
    "        # create the illusion of a border by using hyphens\n",
    "        end = '\\n' + (\n",
    "            '-' * 14\n",
    "        )\n",
    "    )\n",
    "    # display the first ten rows of the dataframe\n",
    "    display(\n",
    "        dataframe.head(\n",
    "            10\n",
    "        )\n",
    "    )\n",
    "    # label the next output\n",
    "    print(\n",
    "        # create the illusion of a border by using hyphens\n",
    "        '\\n',\n",
    "        end = (\n",
    "            '-' * 13\n",
    "        ) + '\\n'\n",
    "    )\n",
    "    print(\n",
    "        'Last Ten Rows',\n",
    "        # create the illusion of a border by using hyphens\n",
    "        end = '\\n' + (\n",
    "            '-' * 13\n",
    "        )\n",
    "    )\n",
    "    # display the last ten rows of the dataframe\n",
    "    display(\n",
    "        dataframe.tail(\n",
    "            10\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary of dataframes and their names\n",
    "sample_datasets = {\n",
    "    'Cocoon Center Pharmacy Items & Reviews': cocoon_pharmacy_df,\n",
    "    'Data Literacy Questionnaire': data_literacy_df,\n",
    "    'Data Journey Questionnaire': data_journey_df,\n",
    "    'Meeting Cadence Survey': meeting_cadence_df\n",
    "}\n",
    "# iterate through (dataframe name - dataframe object) 'key - value' pairs \n",
    "for df_name, df_object in sample_datasets.items():\n",
    "    # display each dataframe's summary information and first/last 10 rows\n",
    "    display_with_info(\n",
    "        df_object,\n",
    "        df_name\n",
    "    )\n",
    "    # add a horizontal border to separate outputs\n",
    "    print(\n",
    "        '\\n' + (\n",
    "            '_' * 79\n",
    "        ),\n",
    "        end = '\\n\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through sample datasets again but display profile report this time\n",
    "for df_name, df_object in sample_datasets.items():\n",
    "    display(\n",
    "        # display the profile report after it's been converted to an iframe\n",
    "        ProfileReport(\n",
    "            # us the dataframe object 'value' from the dictionary\n",
    "            df_object,\n",
    "            # create a title using the dataframe name 'key' from the dictionary\n",
    "            title = f'Profile of {df_name} DataFrame',\n",
    "            # set additional display option for the report\n",
    "            html = {\n",
    "                'navbar_show': True,\n",
    "                'style': {\n",
    "                    'primary_color': '#016ba9',\n",
    "                    'full_width': True\n",
    "                }\n",
    "            },\n",
    "            # don't show a progress bar while the report is being built\n",
    "            progress_bar = False\n",
    "        # iframe objects are necessary to render html in a notebook\n",
    "        ).to_notebook_iframe()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### NUMBER OF REVIEWS PER BRAND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default renderer in plotly to iframe and use online CDN\n",
    "pio.renderers.default = \"iframe_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set matplotlib package to render plots within the notebook cells\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a figure object\n",
    "plt.figure(\n",
    "    # determine an initial size by passing length and width as parameters\n",
    "    figsize = (30,8)\n",
    ")\n",
    "# initialize a plot on the axis by calling seaborn's 'countplot' function\n",
    "ax = sns.countplot(\n",
    "    # use the cocoon pharmacy dataframe as the data for the plot\n",
    "    data = cocoon_pharmacy_df,\n",
    "    # use the 'brand' column for the x axis\n",
    "    x = 'brand',\n",
    "    color = 'blue'\n",
    ")\n",
    "# iterate through each subcomponent (patch) drawn on the axis\n",
    "for p in ax.patches:\n",
    "    # store the value of the subcomponent in a variable\n",
    "    x = p.get_x()\n",
    "    # store the height it's drawn to within the axis\n",
    "    height = p.get_height()\n",
    "    # store the width it's drawn to within the axis\n",
    "    width = p.get_width()\n",
    "    # if it is located below the displayed axis on the figure we can skip it\n",
    "    if pd.isnull(height):\n",
    "        pass\n",
    "    else:\n",
    "        # add the subcomponent's value at its location (label the bars)\n",
    "        ax.text(\n",
    "            x + width/2,\n",
    "            height,\n",
    "            str(height),\n",
    "            ha = 'center',\n",
    "            weight = 'bold',\n",
    "            fontsize = 18\n",
    "        )\n",
    "# rotate the labels on the x-axis and change their font size\n",
    "plt.xticks(\n",
    "    rotation = 45,\n",
    "    fontsize = 18\n",
    ")\n",
    "# change the font size for labels on the y-axis\n",
    "plt.yticks(\n",
    "    fontsize = 18\n",
    ")\n",
    "# add a label to the x-axis\n",
    "plt.xlabel(\n",
    "    'Brand',\n",
    "    fontsize = 25\n",
    ")\n",
    "# add a label to the y-axis\n",
    "plt.ylabel(\n",
    "    'Review Counts',\n",
    "    fontsize = 25\n",
    ")\n",
    "# add a title to the figure\n",
    "plt.title(\n",
    "    'Number of reviews per Brand - Total {}'.format(\n",
    "        # similar to using f' before a string, using .format replaces the {} in\n",
    "        # the string above with the contents of the object below\n",
    "        cocoon_pharmacy_df.shape[0]\n",
    "    ),\n",
    "    size = 30\n",
    ")\n",
    "# display the figure containing the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NUMBER OF REVIEWS PER PRODUCT CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a figure object\n",
    "plt.figure(\n",
    "    # determine an initial size by passing length and width as parameters\n",
    "    figsize = (30,8)\n",
    ")\n",
    "# initialize a plot on the axis by calling seaborn's (sns) 'countplot' function\n",
    "ax = sns.countplot(\n",
    "    # use the cocoon pharmacy dataframe as the data for the plot\n",
    "    data = cocoon_pharmacy_df,\n",
    "    # use the 'product_cat' for the x-axis values\n",
    "    x = 'product_cat',\n",
    "    color = 'blue'\n",
    ")\n",
    "# iterate through each subcomponent (patch) drawn on the axis\n",
    "for p in ax.patches: \n",
    "    # store the value of the subcomponent in a variable\n",
    "    x = p.get_x()\n",
    "    # store the height it's drawn to within the axis\n",
    "    height = p.get_height()\n",
    "    # store the width it's drawn to within the axis\n",
    "    width = p.get_width()\n",
    "    # if it is located below the displayed axis on the figure we can skip it\n",
    "    if pd.isnull(height):\n",
    "        pass\n",
    "    else:   \n",
    "        # add the subcomponent's value at its location (label the bars)\n",
    "        ax.text(\n",
    "            x + width/2,\n",
    "            height,\n",
    "            str(height),\n",
    "            ha = 'center',\n",
    "            weight = 'bold',\n",
    "            fontsize = 18\n",
    "        )\n",
    "# rotate the labels on the x-axis and change their font size\n",
    "plt.xticks(\n",
    "    rotation = 45,\n",
    "    fontsize = 18\n",
    ")\n",
    "# change the font size for labels on the y-axis\n",
    "plt.yticks(\n",
    "    fontsize = 18\n",
    ")\n",
    "# add a label to the x-axis\n",
    "plt.xlabel(\n",
    "    'Product Category', \n",
    "    fontsize = 25\n",
    ")\n",
    "# add label to the y-axis\n",
    "plt.ylabel(\n",
    "    'Review Counts',\n",
    "    fontsize = 25\n",
    ")\n",
    "# add a title to the figure\n",
    "plt.title(\n",
    "    'Number of reviews per Product Category',\n",
    "    fontsize = 30\n",
    ")\n",
    "# display the figure containing the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NUMBER OF REVIEWS PER BRAND AND PRODUCT CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe object to view the forms grouped by category and brand\n",
    "grouped_count_df = cocoon_pharmacy_df.groupby(\n",
    "    # pass a list of columns we want to groupby\n",
    "    [\n",
    "        'product_cat',\n",
    "        'brand'\n",
    "    ]\n",
    "# slice for the 'form' column and get a count\n",
    ")['form'].count().reset_index().rename(\n",
    "    # rename the column to an appropriate label after transforming\n",
    "    {\n",
    "        'form':'Review Count'\n",
    "    },\n",
    "    # axis = 0 means apply to rows, axis = 1 means apply to columns\n",
    "    axis = 1\n",
    "# replace the sliced index (which may be out of order) with a new sequential one\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize a figure object using plotly express' bar plot function\n",
    "fig = px.bar(\n",
    "    # use the dataframe we just created above as the data source for the plot\n",
    "    grouped_count_df,\n",
    "    # use product category for the x-axis\n",
    "    x = 'product_cat',\n",
    "    # use the new review count column for the y-axis\n",
    "    y = 'Review Count', \n",
    "    # color the subplots differently based on the 'brand' column value\n",
    "    color = 'brand',\n",
    "    # use a discrete color sequence made for qualitative values \n",
    "    color_discrete_sequence = px.colors.qualitative.Dark24\n",
    ")\n",
    "# add a label to the x-axis and rotate the ticks\n",
    "fig.update_xaxes(\n",
    "    tickangle = 325,\n",
    "    title = 'Brand'\n",
    ")\n",
    "# add a label to the y-axis\n",
    "fig.update_yaxes(\n",
    "    title = 'Review Counts'\n",
    ")\n",
    "# add a title to the figure\n",
    "fig.update_layout(\n",
    "    # 'title' takes a dictionary argument so multiple properties can be passed\n",
    "    title = dict(\n",
    "        # create a text - title, key - value pair to define that property\n",
    "        text = '<b>Number of reviews per Product Category and Brand</b>',\n",
    "        # font also takes a dictionary to discern different properties\n",
    "        font = dict(\n",
    "            # in this case we only define a size property\n",
    "            size = 24\n",
    "        )\n",
    "    ),\n",
    "    # dictionaries can be created using the dict() function or {k:v} syntax\n",
    "    xaxis = {\n",
    "        # this property tells the plot to sort the xaxis in descending order\n",
    "        'categoryorder': 'total descending'\n",
    "    }\n",
    ")\n",
    "# display the figure containing the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### OVERALL PRICE VARIATION PER BRAND AND PRODUCT CATEGORY COMBINATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new dataframe object to view the unique values in a group of columns\n",
    "brand_product_prices = cocoon_pharmacy_df[\n",
    "    # slice the dataframe for the following list of columns\n",
    "    [\n",
    "        'brand',\n",
    "        'product_cat',\n",
    "        'form',\n",
    "        'volume',\n",
    "        'price'\n",
    "    ]\n",
    "# drop rows with duplicated entries, keeping the last by default \n",
    "].drop_duplicates() # closed parenthesis () tells functions to use default args\n",
    "# overwrite the contents of the volume column by 'assigning' a modified version\n",
    "brand_product_prices['volume'] = brand_product_prices['volume'].replace(\n",
    "    # replace values that say 'not available' with a 'null' object\n",
    "    {\n",
    "        'not available': None\n",
    "    }\n",
    ")\n",
    "# create a new column called price per ml by using existing columns\n",
    "brand_product_prices['price_per_ml'] = brand_product_prices['price'].div(\n",
    "    # use a vectorized operation to divide the prices by the volumes\n",
    "    brand_product_prices['volume'].astype(\n",
    "        # astype function converts the text values in this column to decimals\n",
    "        'float'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a figure object using plotly express' box plot function\n",
    "fig = px.box(\n",
    "    # use the dataframe we just created above as the data source\n",
    "    brand_product_prices,\n",
    "    # use brand for the x-axis\n",
    "    x = 'brand',\n",
    "    # use the new price per milliliter column for the y-axis\n",
    "    y = 'price_per_ml',\n",
    "    # color the subplots based on the 'product category' column value\n",
    "    color = 'product_cat',\n",
    "    # show all points instead of hiding outliers past a certain threshold\n",
    "    points = 'all'\n",
    ")\n",
    "# add a label to the x-axis and rotate the ticks\n",
    "fig.update_xaxes(\n",
    "    tickangle = 325,\n",
    "    title = 'Brand'\n",
    ")\n",
    "# add a label to the y-axis\n",
    "fig.update_yaxes(\n",
    "    title = 'Price per ml'\n",
    ")\n",
    "# add a title to the figure\n",
    "fig.update_layout(\n",
    "    title = 'PRICE VARIATION PER BRAND AND PRODUCT CATEGORY'\n",
    ")\n",
    "# add text to the title in the figure\n",
    "fig.update_layout(\n",
    "    # 'title' parameter takes a dictionary so multiple arguments can be passed\n",
    "    title = dict(\n",
    "        # add subtitle\n",
    "        text = '<b>Price variation per product and brand</b>',\n",
    "        # 'font' also takes a dictionary but we are just changing one property\n",
    "        font = dict(\n",
    "            size = 24\n",
    "        )\n",
    "    )\n",
    ")\n",
    "# display the figure containing the plot\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANALYZING CUSTOMER LOCATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up text in the customer locations column by 'redefining' the object\n",
    "cocoon_pharmacy_df['customer_loc'] = cocoon_pharmacy_df['customer_loc']\\\n",
    ".str.strip(  # remove whitespace from the ends of each string (text object)\n",
    ").str.lower( # turn all characters into lowercase\n",
    ").replace(\n",
    "    # replace vague and unused labels\n",
    "    {\n",
    "        'the kingdom':'saudi arabia',\n",
    "        'good':None,\n",
    "        'not available':None,\n",
    "        'ksa':'saudi arabia',\n",
    "        'the kingdom':'saudi arabia',\n",
    "        'london o':'london, ontario',\n",
    "        'cheshire':'cheshire, uk',\n",
    "        '-':None,\n",
    "        'sale, cheshire':'sale, cheshire, uk',\n",
    "        'tilbury, essex':'tilbury, essex, uk',\n",
    "        'middle east':'ksa middle east',\n",
    "        'kingston':'kingston, uk',\n",
    "        'awali':'awali, bahrain',\n",
    "        'riyadh, s. a.':'riyadh, saudi arabia',\n",
    "        'north':None,\n",
    "        'south east':None,\n",
    "        'memo':None\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize geolocator object to get coordinates from location names\n",
    "geolocator = geopy_Nominatim(\n",
    "    user_agent = \"s\"\n",
    ")\n",
    "# example output of coordinates based on a location\n",
    "geolocator.geocode(\"Abu Dhabi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create columns with coordinates for the customer locations\n",
    "new_cocoon_df = cocoon_pharmacy_df.assign(\n",
    "    Customer_Location_Latitude_Longitude = cocoon_pharmacy_df['customer_loc'].apply(\n",
    "        # lamdda denotes an anonymous function where the 'caller' is the 'input'\n",
    "        # in this case if the value is not null we want to get the 'geocode'\n",
    "        lambda x: geolocator.geocode(x) if pd.notnull(\n",
    "            geolocator.geocode(x)\n",
    "        ) else None # otherwise we leave null values alone\n",
    "    ),\n",
    "    # use the column created in the lines above to create the two columns below\n",
    "    Latitude = cocoon_pharmacy_df['Customer_Location_Latitude_Longitude'].apply(\n",
    "        lambda x: x.latitude if pd.notnull(x) else None\n",
    "    ),\n",
    "    Longitude = cocoon_pharmacy_df['Customer_Location_Latitude_Longitude'].apply(\n",
    "        lambda x: x.longitude if pd.notnull(x) else None\n",
    "    )\n",
    ")\n",
    "# get list of columns in the dataframe excluding the ones pertaining to coordinates\n",
    "columns_without_customer_location = set(\n",
    "    new_cocoon_df.columns\n",
    ").difference(\n",
    "    [\n",
    "        'Customer_Location_Latitude_Longitude',\n",
    "        'Latitude',\n",
    "        'Longitude'\n",
    "    ]\n",
    ")\n",
    "# slice the dataframe for rows and columns without duplicates in the non-coordinate columns\n",
    "new_cocoon_df = new_cocoon_df.loc[\n",
    "    # slice the dataframe for columns without location and then drop the duplicates\n",
    "    new_cocoon_df[columns_without_customer_location].drop_duplicates(\n",
    "        # keep the first instance of a duplicate\n",
    "        keep  = 'first'\n",
    "    # use the index of this 'de-duped' dataframe to slice for the 'first' instance of each\n",
    "    ).index,\n",
    "    # ':' by itself denotes 'all' columns\n",
    "    :\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the modified dataframe as a .csv file in the 'data' folder\n",
    "new_cocoon_df.to_csv(\n",
    "    '../data/cocoon_pharmacy_location_added.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GEOGRAPHIC LOCATION OF REVIEWERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite the 'cocoon_pharmacy_df' object with a dataframe of our 'new' file\n",
    "cocoon_pharmacy_df = pd.read_csv(\n",
    "    '../data/cocoon_pharmacy_location_added.csv',\n",
    "    # this dataframe was stored as .csv, with the index in the first position\n",
    "    index_col = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# initialize a figure by using plotly express' geographic scatter plot function\n",
    "fig = px.scatter_geo(\n",
    "    # use the 'new' dataframe which has customer location coordinates\n",
    "    cocoon_pharmacy_df,\n",
    "    # use the column named 'Latitude' for latitude coordinates\n",
    "    lat = 'Latitude',\n",
    "    # use the column named 'Longitude' for Longitude coordinates\n",
    "    lon = 'Longitude',\n",
    "    # use customer location text to label the box that appears when hovering\n",
    "    hover_name = 'customer_loc'\n",
    ")\n",
    "# set properties for the map the plot will be drawn on\n",
    "fig.update_geos(\n",
    "    # set a resolution for the rendered image\n",
    "    resolution = 50,\n",
    "    # show land on the map\n",
    "    showland = True,\n",
    "    # make the land light green\n",
    "    landcolor = \"LightGreen\",\n",
    "    # show oseans on the map\n",
    "    showocean = True, \n",
    "    # make the oceans light blue\n",
    "    oceancolor = \"LightBlue\"\n",
    ")\n",
    "# set the margins of the dynamic figure and add a gray background\n",
    "fig.update_layout(\n",
    "    margin = dict(\n",
    "        l = 5,\n",
    "        r = 5,\n",
    "        t = 25,\n",
    "        b = 5\n",
    "    ),\n",
    "    paper_bgcolor = \"lightGrey\"\n",
    ")\n",
    "# set new subplot properties\n",
    "fig.update_traces(\n",
    "    marker = dict(\n",
    "        size = 9,\n",
    "        color = 'yellow',\n",
    "        opacity = 0.6\n",
    "    )\n",
    ")\n",
    "# add a title to the figure\n",
    "fig.update_layout(\n",
    "    title = 'Customer Locations, Cocoon Pharmacy'\n",
    ")\n",
    "# display the figure containing the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEXT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through list of components to download from the NLTK library\n",
    "for component in [\n",
    "    'punkt',\n",
    "    'stopwords',\n",
    "    'averaged_perceptron_tagger',\n",
    "    'wordnet',\n",
    "    'omw-1.4'\n",
    "]:\n",
    "    # use nltk's download function to pull the components\n",
    "    nltk.download(\n",
    "        component\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the column containing the text body of the customer reviews\n",
    "cocoon_pharmacy_df['body_review'] = cocoon_pharmacy_df['body_review']\\\n",
    ".str.lower( # convert all the text in the reviews to lowercase \n",
    ").apply( \n",
    "    # apply an anonymous function to remove all special characters\n",
    "    lambda x:  re.sub(\n",
    "        r'[^\\w\\s]',\n",
    "        '',\n",
    "        x\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to generate a wordcloud for a given dataframe\n",
    "def make_wordcloud(\n",
    "    # takes one positional argument of Pandas DataFrame type named 'df'\n",
    "    df: pd.DataFrame\n",
    "# returns a wordcloud object\n",
    ") -> WordCloud:\n",
    "    # create an string object of all the words in all the reviews in the frame\n",
    "    all_words = ' '.join( # each review body will be separated by empty space\n",
    "        # assumes each dataframe has a column named 'body_review'\n",
    "        df['body_review']\n",
    "    )\n",
    "    # create an object of the tokens in all reviews in a dataframe\n",
    "    tokenized_words = nltk_word_tokenize(\n",
    "        # this separatesa a continuous string of text into a list of words  \n",
    "        all_words\n",
    "    )\n",
    "    # create set of unique english 'stopwords' (i.e. 'and', 'to', 'of')\n",
    "    # curly brackets without a key-value pair creates a set, which is an \n",
    "    # unordered container of unique objects, meaning duplicates are removed\n",
    "    english_stops = {\n",
    "        # the asterisk '*' at the beginning unpacks the list's contents so all\n",
    "        # the items within are passed instead of just the container object\n",
    "        *nltk_stopwords.words(\n",
    "            # passing a language generates the list of all stopwords nltk has for it \n",
    "            'english'\n",
    "        )\n",
    "    }\n",
    "    # create string of all tokenized words that fit some conditions\n",
    "    all_tokens = ' '.join( # each token will be separated by empty space\n",
    "        # by using an expression we can 'generate' the contents of a list\n",
    "        [\n",
    "            # list will contain tokens from the tokenized_words object above\n",
    "            token for token in tokenized_words if ( \n",
    "                # first condition checks tokens are longer than 2 characters\n",
    "                len(token) > 2 \n",
    "            ) and (  # and statement means both conditions must be true\n",
    "                # second condition checks tokens are not a stopword\n",
    "                token not in english_stops # not found in stopword list\n",
    "            ) and (  # chaining and statements allows us to enforce multiple\n",
    "                # third condition checks the token is not an empty string\n",
    "                pd.notna(token)\n",
    "            ) and (  # placing conditions in parenthesis is not necessary but improves readability\n",
    "                # fourth condition checks the token consists only of letters\n",
    "                token.isalpha()\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    # initialize the WordNetLemmatizer from the 'Natural Language Tool Kit'\n",
    "    lemmatizer = nltk_WordNetLemmatizer() # closed parenthesis since it's a call not an object\n",
    "    # use the 'Part of Speech' tagger to add what each word token is\n",
    "    parts_of_speech = nltk_pos_tag( # adds label to tag as 'noun', 'verb', etc.\n",
    "        # create new list of tokens from those that passed the conditions above\n",
    "        # i.e. [('word', 'wordtype'), (.., ..)] with a pair of values for each word\n",
    "        nltk_word_tokenize(\n",
    "            all_tokens\n",
    "        )\n",
    "    )\n",
    "    # initialize the final object that will contain the wordcloud text  \n",
    "    wordcloud_tokens = ''\n",
    "    # iterate through a list of integers of size equal to the number of tokens\n",
    "    for i in range( # generates a list from 0 to the number passed by default\n",
    "        # len function outputs the number of objects in a container object\n",
    "        len(\n",
    "            # in this case parts_of_speech is a list of labeled tokens\n",
    "            parts_of_speech\n",
    "        )\n",
    "    ):  # NOTE: the objects under an indented block are overwritten during each run \n",
    "        # [] notationa at the end of an object lets us access its contents\n",
    "        if \"V\" in parts_of_speech[i][1][0]:\n",
    "            ''' NOTE: triple quotes can be used to create a multi-line comment\n",
    "            The line above is best read in reverse order, it states that if\n",
    "            the list in position 0 (first) of the object at position 1 (second) \n",
    "            of the object at position i (which is the value we're iterating) \n",
    "            in the parts of speech list contains the string 'v', then we \n",
    "            create a temporary object with a value of 'v'\n",
    "            '''\n",
    "            pos = 'v'\n",
    "        else:\n",
    "            # otherwise we create the same object but with a value of 'n'\n",
    "            pos = 'n'\n",
    "        # use the lemmatizer object to group words with inflections together\n",
    "        lem = lemmatizer.lemmatize(\n",
    "            # takes the word itself, which is the first object in each pair in the list\n",
    "            parts_of_speech[i][0],\n",
    "            # use the part-of-speech tag from if/else block above to tell the \n",
    "            # lemmatizer what it needs to group each word with (i.e. nouns or verbs) \n",
    "            pos\n",
    "        )\n",
    "        # add the lemmatized token to the output string with a space to separate it\n",
    "        wordcloud_tokens += (lem) + ' ' # += tells python to add to the object and not overwrite it\n",
    "    # generate wordcloud and store it in an object\n",
    "    wordcloud_from_reviews = WordCloud(\n",
    "        # pass some settings to the initalization of the object such as stopwords to remove\n",
    "        stopwords = wordcloud_STOPWORDS,\n",
    "        # what percentage of the words should be displayed horizontally\n",
    "        prefer_horizontal = 0.9,\n",
    "        # the maximum number of words to display\n",
    "        max_words = 100\n",
    "    ).generate( # call the generate function from the just initialized object\n",
    "        # pass the tokens that have been cleaned, vetted, and lemmatized\n",
    "        wordcloud_tokens\n",
    "    )\n",
    "    # return the wordcloud object when the function is called\n",
    "    return wordcloud_from_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a figure with one row and four columns to fit multiple subplots\n",
    "fig,ax = plt.subplots(\n",
    "    nrows = 1,\n",
    "    ncols = 4,\n",
    "    figsize = (25,10)\n",
    ")\n",
    "# initialize an object to track the columns in the figure housing the wordclouds \n",
    "column_num = 0\n",
    "# iterate through a list of the top five product categories in descending order\n",
    "for category in cocoon_pharmacy_df['product_cat'].value_counts( # counts the occurrence of each value in 'product_cat'\n",
    ").sort_values(\n",
    "    # sorts the values by descending order of their frequency\n",
    "    ascending = False\n",
    "# a colon inside brackets lets us slice for all values up to (or from) a position\n",
    "# .index grabs the labels for the rows in the dataframe, in this case the categories themselves\n",
    ")[:4].index:\n",
    "    # display the category we're iterating through\n",
    "    print(\n",
    "        category\n",
    "    )\n",
    "    # add a wordcloud to the figure at the 'column_num' column in the axis (i.e. 0 = first)  \n",
    "    ax[column_num].imshow(\n",
    "        # call the function we defined earlier to create wordclouds from a dataframe\n",
    "        make_wordcloud(\n",
    "            # pass a slice of the dataframe with all rows of the category we're iterating through\n",
    "            cocoon_pharmacy_df[cocoon_pharmacy_df['product_cat'] == category]\n",
    "        )\n",
    "    )\n",
    "    # turn off the ticks to just display the image drawn on the figure\n",
    "    ax[column_num].axis(\"off\")\n",
    "    # add a title to the figure\n",
    "    ax[column_num].set_title(\n",
    "        # f' syntax lets us replace the contents of a {} with the value of an object\n",
    "        f'Wordcloud - {category}', # e.g 'Wordcloud - Skincare' if category = 'Skincare' \n",
    "        fontsize = 18\n",
    "    )\n",
    "    # increment the column number so the next iteration adds a figure to the next column\n",
    "    column_num += 1\n",
    "# remove whitespace around the edges of the image in the figure\n",
    "fig.tight_layout()\n",
    "# display the figure containing the plots\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 ('dbr-10_4ml-base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "065e060c6089993c74c9bf4b911d37e59dadeed66bb03a666c87bc53eaee6720"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
